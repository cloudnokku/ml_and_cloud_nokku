{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sagemaker\n",
      "  Downloading sagemaker-2.173.0.tar.gz (854 kB)\n",
      "\u001b[K     |████████████████████████████████| 854 kB 711 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML~=6.0 in /home/prudhvinokku/ml-cloud-nokku/.venv/lib/python3.8/site-packages (from sagemaker->-r deployment_requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /home/prudhvinokku/ml-cloud-nokku/.venv/lib/python3.8/site-packages (from sagemaker->-r deployment_requirements.txt (line 1)) (23.1.0)\n",
      "Collecting boto3<2.0,>=1.26.131\n",
      "  Downloading boto3-1.28.17-py3-none-any.whl (135 kB)\n",
      "\u001b[K     |████████████████████████████████| 135 kB 27.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cloudpickle==2.2.1\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Collecting google-pasta\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 7.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/prudhvinokku/ml-cloud-nokku/.venv/lib/python3.8/site-packages (from sagemaker->-r deployment_requirements.txt (line 1)) (6.8.0)\n",
      "Requirement already satisfied: jsonschema in /home/prudhvinokku/ml-cloud-nokku/.venv/lib/python3.8/site-packages (from sagemaker->-r deployment_requirements.txt (line 1)) (4.18.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/prudhvinokku/ml-cloud-nokku/.venv/lib/python3.8/site-packages (from sagemaker->-r deployment_requirements.txt (line 1)) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/prudhvinokku/ml-cloud-nokku/.venv/lib/python3.8/site-packages (from sagemaker->-r deployment_requirements.txt (line 1)) (23.1)\n",
      "Requirement already satisfied: pandas in /home/prudhvinokku/ml-cloud-nokku/.venv/lib/python3.8/site-packages (from sagemaker->-r deployment_requirements.txt (line 1)) (2.0.3)\n",
      "Collecting pathos\n",
      "  Downloading pathos-0.3.1-py3-none-any.whl (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 314 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: platformdirs in /home/prudhvinokku/ml-cloud-nokku/.venv/lib/python3.8/site-packages (from sagemaker->-r deployment_requirements.txt (line 1)) (3.10.0)\n",
      "Collecting protobuf<5.0,>=3.12\n",
      "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "\u001b[K     |████████████████████████████████| 304 kB 13.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting schema\n",
      "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
      "Collecting smdebug_rulesconfig==1.0.1\n",
      "  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\n",
      "Collecting tblib==1.7.0\n",
      "  Downloading tblib-1.7.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Using cached s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
      "Collecting botocore<1.32.0,>=1.31.17\n",
      "  Downloading botocore-1.31.17-py3-none-any.whl (11.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.1 MB 16.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /home/prudhvinokku/ml-cloud-nokku/.venv/lib/python3.8/site-packages (from google-pasta->sagemaker->-r deployment_requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/prudhvinokku/ml-cloud-nokku/.venv/lib/python3.8/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker->-r deployment_requirements.txt (line 1)) (3.16.2)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/prudhvinokku/ml-cloud-nokku/.venv/lib/python3.8/site-packages (from jsonschema->sagemaker->-r deployment_requirements.txt (line 1)) (0.30.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/prudhvinokku/ml-cloud-nokku/.venv/lib/python3.8/site-packages (from jsonschema->sagemaker->-r deployment_requirements.txt (line 1)) (2023.7.1)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10; python_version < \"3.9\" in /home/prudhvinokku/ml-cloud-nokku/.venv/lib/python3.8/site-packages (from jsonschema->sagemaker->-r deployment_requirements.txt (line 1)) (1.3.10)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/prudhvinokku/ml-cloud-nokku/.venv/lib/python3.8/site-packages (from jsonschema->sagemaker->-r deployment_requirements.txt (line 1)) (0.9.2)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0; python_version < \"3.9\" in /home/prudhvinokku/ml-cloud-nokku/.venv/lib/python3.8/site-packages (from jsonschema->sagemaker->-r deployment_requirements.txt (line 1)) (6.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/prudhvinokku/ml-cloud-nokku/.venv/lib/python3.8/site-packages (from pandas->sagemaker->-r deployment_requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/prudhvinokku/ml-cloud-nokku/.venv/lib/python3.8/site-packages (from pandas->sagemaker->-r deployment_requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/prudhvinokku/ml-cloud-nokku/.venv/lib/python3.8/site-packages (from pandas->sagemaker->-r deployment_requirements.txt (line 1)) (2.8.2)\n",
      "Collecting pox>=0.3.3\n",
      "  Downloading pox-0.3.3-py3-none-any.whl (29 kB)\n",
      "Collecting ppft>=1.7.6.7\n",
      "  Downloading ppft-1.7.6.7-py3-none-any.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 7.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting dill>=0.3.7\n",
      "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[K     |████████████████████████████████| 115 kB 28.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multiprocess>=0.70.15\n",
      "  Downloading multiprocess-0.70.15-py38-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 18.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting contextlib2>=0.5.5\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting urllib3<1.27,>=1.25.4\n",
      "  Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.173.0-py2.py3-none-any.whl size=1163264 sha256=cb4c07541e0f55fa816f9cc9606b4d1e486223265322d0f600a912ac51661574\n",
      "  Stored in directory: /home/prudhvinokku/.cache/pip/wheels/ca/c9/9d/fbe1071761d8a623c214ce3c8fef2b05370156afd5274e2c4c\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: jmespath, urllib3, botocore, s3transfer, boto3, cloudpickle, google-pasta, pox, ppft, dill, multiprocess, pathos, protobuf, contextlib2, schema, smdebug-rulesconfig, tblib, sagemaker\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.0.3\n",
      "    Uninstalling urllib3-2.0.3:\n",
      "      Successfully uninstalled urllib3-2.0.3\n",
      "Successfully installed boto3-1.28.17 botocore-1.31.17 cloudpickle-2.2.1 contextlib2-21.6.0 dill-0.3.7 google-pasta-0.2.0 jmespath-1.0.1 multiprocess-0.70.15 pathos-0.3.1 pox-0.3.3 ppft-1.7.6.7 protobuf-4.23.4 s3transfer-0.6.1 sagemaker-2.173.0 schema-0.7.5 smdebug-rulesconfig-1.0.1 tblib-1.7.0 urllib3-1.26.16\n"
     ]
    }
   ],
   "source": [
    "!pip install -r deployment_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-21 11:14:13 aws-sam-cli-managed-default-samclisourcebucket-1wvml9o4wtjkt\n",
      "2022-10-06 10:47:47 sagemaker-studio-z8z2mmtoy7b\n",
      "2022-10-06 10:53:01 sagemaker-us-east-1-927437237063\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::927437237063:role/my-sagemaker-exec-role\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "# sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "# sagemaker_session_bucket=None\n",
    "# if sagemaker_session_bucket is None and sess is not None:\n",
    "#     # set to default bucket if a bucket name is not given\n",
    "#     sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "sagemaker_session_bucket = \"sagemaker-us-east-1-927437237063\"\n",
    "# try:\n",
    "#     role = sagemaker.get_execution_role()\n",
    "# except ValueError:\n",
    "#     iam = boto3.client('iam')\n",
    "#     role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "role = \"arn:aws:iam::927437237063:role/my-sagemaker-exec-role\"\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm image uri: 763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.0-tgi0.8.2-gpu-py39-cu118-ubuntu20.04\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# retrieve the llm image uri\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "  \"huggingface\",\n",
    "  version=\"0.8.2\"\n",
    ")\n",
    "\n",
    "# print ecr image uri\n",
    "print(f\"llm image uri: {llm_image}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# sagemaker config\n",
    "# instance_type = \"ml.g5.12xlarge\"\n",
    "instance_type = \"ml.g5.xlarge\"\n",
    "number_of_gpu = 1\n",
    "health_check_timeout = 300\n",
    "\n",
    "# Define Model and Endpoint configuration parameter\n",
    "config = {\n",
    "  'HF_MODEL_ID': \"google/flan-t5-small\", # model_id from hf.co/models\n",
    "  'SM_NUM_GPUS': json.dumps(number_of_gpu), # Number of GPU used per replica\n",
    "#   'MAX_INPUT_LENGTH': json.dumps(1024),  # Max length of input text\n",
    "#   'MAX_TOTAL_TOKENS': json.dumps(2048),  # Max length of the generation (including input text)\n",
    "  # 'HF_MODEL_QUANTIZE': \"bitsandbytes\", # comment in to quantize\n",
    "}\n",
    "\n",
    "# create HuggingFaceModel with the image uri\n",
    "llm_model = HuggingFaceModel(\n",
    "  role=role,\n",
    "  image_uri=llm_image,\n",
    "  env=config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy model to an endpoint\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy\n",
    "llm = llm_model.deploy(\n",
    "  initial_instance_count=1,\n",
    "  instance_type=instance_type,\n",
    "  wait=False,\n",
    "  # volume_size=400, # If using an instance with local SSD storage, volume_size must be None, e.g. p4 but not p3\n",
    "  container_startup_health_check_timeout=health_check_timeout, # 10 minutes to be able to load the model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Meine Namen ist Arthur.'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict({\n",
    "\t\"inputs\": \"Translate to German:  My name is Arthur\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
